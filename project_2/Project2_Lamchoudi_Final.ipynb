{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bank Customer Churn Using Frameworks\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The dataset is for an international bank with millions of clients, mostly in Spain, France, and Germany, but also throughout all of Europe. The bank decided to take action after noticing that customer attrition rates had started to rise relative to the typical rate over the previous six months. The bank made the decision to select a random sample of 10,000 of its clients in order to gather some data.\n",
        "\n",
        "They observed the behavior of these 10,000 customers over a period of six months and examined who remained in the bank and who left. They therefore want us to create a model that can calculate the likelihood that a customer will leave the bank.\n",
        "\n",
        "The objective of this work is to develop a geodemographic segmentation model that will inform the bank of which clients are most likely to depart.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mzy0OpkG3Gjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "I will start by importing the necessary libraries."
      ],
      "metadata": {
        "id": "fIRcLSzo3LWF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUQpuf72yho",
        "outputId": "b87ef87d-d1a9-4abc-8227-450460b2f40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.13.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.colors import n_colors\n",
        "from plotly.subplots import make_subplots\n",
        "import copy\n",
        "import scipy\n",
        "import random\n",
        "import math\n",
        "!pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Feature Scaling (very important)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Import Keras library and packages\n",
        "import keras\n",
        "import sys\n",
        "from keras.models import Sequential #to initialize NN\n",
        "from keras.layers import Dense #used to create layers in NN\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.metrics import (accuracy_score, f1_score,average_precision_score, confusion_matrix,\n",
        "                             average_precision_score, precision_score, recall_score, roc_auc_score, )\n",
        "from mlxtend.plotting import plot_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Bank_Customer_Churn_Prediction.csv')"
      ],
      "metadata": {
        "id": "eAeXjsyv3fK0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "s41_mtJp37Hl",
        "outputId": "78a5a0c4-143c-490e-a4aa-d8599b3eeba6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   customer_id  credit_score country  gender  age  tenure    balance  \\\n",
              "0     15634602           619  France  Female   42       2       0.00   \n",
              "1     15647311           608   Spain  Female   41       1   83807.86   \n",
              "2     15619304           502  France  Female   42       8  159660.80   \n",
              "3     15701354           699  France  Female   39       1       0.00   \n",
              "4     15737888           850   Spain  Female   43       2  125510.82   \n",
              "\n",
              "   products_number  credit_card  active_member  estimated_salary  churn  \n",
              "0                1            1              1         101348.88      1  \n",
              "1                1            0              1         112542.58      0  \n",
              "2                3            1              0         113931.57      1  \n",
              "3                2            0              0          93826.63      0  \n",
              "4                1            1              1          79084.10      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80d32a9b-e676-4d87-9fae-efb38b31f4d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15634602</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15647311</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15619304</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15701354</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15737888</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80d32a9b-e676-4d87-9fae-efb38b31f4d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80d32a9b-e676-4d87-9fae-efb38b31f4d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80d32a9b-e676-4d87-9fae-efb38b31f4d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us6Ok-UI38wZ",
        "outputId": "e5c28e35-379e-4b9b-b26f-e7db6f6e29af"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customer_id       10000 non-null  int64  \n",
            " 1   credit_score      10000 non-null  int64  \n",
            " 2   country           10000 non-null  object \n",
            " 3   gender            10000 non-null  object \n",
            " 4   age               10000 non-null  int64  \n",
            " 5   tenure            10000 non-null  int64  \n",
            " 6   balance           10000 non-null  float64\n",
            " 7   products_number   10000 non-null  int64  \n",
            " 8   credit_card       10000 non-null  int64  \n",
            " 9   active_member     10000 non-null  int64  \n",
            " 10  estimated_salary  10000 non-null  float64\n",
            " 11  churn             10000 non-null  int64  \n",
            "dtypes: float64(2), int64(8), object(2)\n",
            "memory usage: 937.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "dDZascoQ4B8V",
        "outputId": "a3b3766c-4d28-4c41-a97c-78985127a4cc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        customer_id  credit_score           age        tenure        balance  \\\n",
              "count  1.000000e+04  10000.000000  10000.000000  10000.000000   10000.000000   \n",
              "mean   1.569094e+07    650.528800     38.921800      5.012800   76485.889288   \n",
              "std    7.193619e+04     96.653299     10.487806      2.892174   62397.405202   \n",
              "min    1.556570e+07    350.000000     18.000000      0.000000       0.000000   \n",
              "25%    1.562853e+07    584.000000     32.000000      3.000000       0.000000   \n",
              "50%    1.569074e+07    652.000000     37.000000      5.000000   97198.540000   \n",
              "75%    1.575323e+07    718.000000     44.000000      7.000000  127644.240000   \n",
              "max    1.581569e+07    850.000000     92.000000     10.000000  250898.090000   \n",
              "\n",
              "       products_number  credit_card  active_member  estimated_salary  \\\n",
              "count     10000.000000  10000.00000   10000.000000      10000.000000   \n",
              "mean          1.530200      0.70550       0.515100     100090.239881   \n",
              "std           0.581654      0.45584       0.499797      57510.492818   \n",
              "min           1.000000      0.00000       0.000000         11.580000   \n",
              "25%           1.000000      0.00000       0.000000      51002.110000   \n",
              "50%           1.000000      1.00000       1.000000     100193.915000   \n",
              "75%           2.000000      1.00000       1.000000     149388.247500   \n",
              "max           4.000000      1.00000       1.000000     199992.480000   \n",
              "\n",
              "              churn  \n",
              "count  10000.000000  \n",
              "mean       0.203700  \n",
              "std        0.402769  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-101a852f-2a6e-42c4-bea1-0d367b4e8687\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>650.528800</td>\n",
              "      <td>38.921800</td>\n",
              "      <td>5.012800</td>\n",
              "      <td>76485.889288</td>\n",
              "      <td>1.530200</td>\n",
              "      <td>0.70550</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>100090.239881</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.193619e+04</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>0.45584</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>0.402769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.556570e+07</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.562853e+07</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51002.110000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>652.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97198.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100193.915000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>718.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127644.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149388.247500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.581569e+07</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-101a852f-2a6e-42c4-bea1-0d367b4e8687')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-101a852f-2a6e-42c4-bea1-0d367b4e8687 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-101a852f-2a6e-42c4-bea1-0d367b4e8687');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i72Xcau4DjF",
        "outputId": "ebc322f3-402a-438f-ca4a-f6dbe5ea188e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['customer_id', 'credit_score', 'country', 'gender', 'age', 'tenure',\n",
              "       'balance', 'products_number', 'credit_card', 'active_member',\n",
              "       'estimated_salary', 'churn'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handeling Categorical Data"
      ],
      "metadata": {
        "id": "E4wKtNMI4I_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns = ['country', 'gender'])"
      ],
      "metadata": {
        "id": "-Pr3cf_s4E1G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNzw12cY4enn",
        "outputId": "3bfb6720-f0b1-4c38-c0b0-985456cf84aa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['customer_id', 'credit_score', 'age', 'tenure', 'balance',\n",
              "       'products_number', 'credit_card', 'active_member', 'estimated_salary',\n",
              "       'churn', 'country_France', 'country_Germany', 'country_Spain',\n",
              "       'gender_Female', 'gender_Male'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separate the Data\n",
        "Lets seperate the predictors X form the target variable y"
      ],
      "metadata": {
        "id": "jyoPHTEt44KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['credit_score', 'age', 'tenure', 'balance',\n",
        "       'products_number', 'credit_card', 'active_member', 'estimated_salary','country_France', 'country_Germany', 'country_Spain',\n",
        "       'gender_Female', 'gender_Male']].values\n",
        "y = df[['churn']].values"
      ],
      "metadata": {
        "id": "xuWD04RL5QO3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[:10,:], '\\n')\n",
        "print(y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViWAIeH35SOL",
        "outputId": "5aab3f21-e6ef-451c-9323-30678d915e7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.1900000e+02 4.2000000e+01 2.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 1.0134888e+05 1.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            " [6.0800000e+02 4.1000000e+01 1.0000000e+00 8.3807860e+04 1.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 1.1254258e+05 0.0000000e+00 0.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            " [5.0200000e+02 4.2000000e+01 8.0000000e+00 1.5966080e+05 3.0000000e+00\n",
            "  1.0000000e+00 0.0000000e+00 1.1393157e+05 1.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            " [6.9900000e+02 3.9000000e+01 1.0000000e+00 0.0000000e+00 2.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 9.3826630e+04 1.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            " [8.5000000e+02 4.3000000e+01 2.0000000e+00 1.2551082e+05 1.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 7.9084100e+04 0.0000000e+00 0.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            " [6.4500000e+02 4.4000000e+01 8.0000000e+00 1.1375578e+05 2.0000000e+00\n",
            "  1.0000000e+00 0.0000000e+00 1.4975671e+05 0.0000000e+00 0.0000000e+00\n",
            "  1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
            " [8.2200000e+02 5.0000000e+01 7.0000000e+00 0.0000000e+00 2.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 1.0062800e+04 1.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
            " [3.7600000e+02 2.9000000e+01 4.0000000e+00 1.1504674e+05 4.0000000e+00\n",
            "  1.0000000e+00 0.0000000e+00 1.1934688e+05 0.0000000e+00 1.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            " [5.0100000e+02 4.4000000e+01 4.0000000e+00 1.4205107e+05 2.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 7.4940500e+04 1.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
            " [6.8400000e+02 2.7000000e+01 2.0000000e+00 1.3460388e+05 1.0000000e+00\n",
            "  1.0000000e+00 1.0000000e+00 7.1725730e+04 1.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 1.0000000e+00]] \n",
            "\n",
            "[[1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data\n",
        "In order to train our model and later test its accuracy, we need to split the data into two datasets. In ANN feature scaling is very important so that all inputs are at a comparable range and only the weights assigned to them are, in fact, the only factor which makes a difference on the predicted value."
      ],
      "metadata": {
        "id": "tzk_h8wy6MnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Feature Scaling (very important)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "Fm46uqRw5XYo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYJpNmU-6YnH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Deep Neuarl Network"
      ],
      "metadata": {
        "id": "-OSuSoGp6buO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the weights\n",
        "I will try \"He Initialization\"; this is named for the first author of He et al., 2015. (If you have heard of \"Xavier initialization\", this is similar except Xavier initialization uses a scaling factor for the weights $W^{[l]}$ of `sqrt(1./layers_dims[l-1])` where He initialization would use `sqrt(2./layers_dims[l-1])`.)\n",
        "\n",
        "**Initialize_parameters_he**\n",
        "\n",
        "Implement the following function to initialize your parameters with He initialization. This function is similar to the previous `initialize_parameters_random(...)`. The only difference is that instead of multiplying `np.random.randn(..,..)` by 10, you will multiply it by $\\sqrt{\\frac{2}{\\text{dimension of the previous layer}}}$, which is what He initialization recommends for layers with a ReLU activation.\n",
        "\n",
        "**Note:**\n",
        "I have a notebbok where I am comparing different initialization methods: Link"
      ],
      "metadata": {
        "id": "52-DC6gG6shd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regullarization Technique: L2\n",
        "To use it in tensorflow, we need to set the kernel_regularizer='l2'"
      ],
      "metadata": {
        "id": "fVulZurfS4Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Normalization\n",
        "Related to what we learnt in class, Batch Norm (BN) is one of the most exciting innovations in optimizing deep Neural Networks. Itâ€™s not an algorithm, it is a method of adaptive re-parametrization motivated by the difficulty of training very deep models. It reduces the problem of internal covariate shift and coordinating updates across many layer.\n",
        "In my model, I will use the BN in every hidden layer.\n",
        "\n",
        "To use the BN in tendorflow, I need just to add BatchNormalization() to the concerned layer."
      ],
      "metadata": {
        "id": "hk_Gj8Tl_YPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features\n",
        "Distribute features of the first observation, from your dataset, per each node in the input layer. Thus, thirteen independent variables will be added to our input layer."
      ],
      "metadata": {
        "id": "5ktKlCM07ix9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Layer\n",
        "**units:** number of nodes in the hidden layer.\n",
        "**kernel_initializer:** it is the initialization method. As I said I will use He initialization\n",
        "**activation:** the activation function\n",
        "**input_dim:** number of nodes in the input layer, that our hidden layer should be expecting"
      ],
      "metadata": {
        "id": "ptXqE8hz8AdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#Initialising the Model - Defining as a sequence of layers or a Graph\n",
        "classifier = Sequential()\n",
        "#Input Layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'relu', input_dim = 13 ))\n",
        "classifier.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "UznrJnWK9qgK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWLaszdv_OZo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hidden Layers\n",
        "From the input to the output the neurons are activated, and the impact they have in the predicted results is measured by the assigned weights. Depending on the number of hidden layers, the system propagates the activation until getting the predicted result y.\n",
        "\n",
        "For the hidden layers, I will use **ReLU** as an activation function, **He initialization**, and ,for sure, the **BN**."
      ],
      "metadata": {
        "id": "af8mEFgrAqJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Second Hidden Layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#Third Hidden Layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "#The Fourth Hidden Layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'relu'))\n",
        "classifier.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "enZ_zCjuBN0I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Layer\n"
      ],
      "metadata": {
        "id": "ycTNJVw-ENl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units = 1, kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'sigmoid'))\n",
        "#classifier.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "VX4bU26xB2Rf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimize the Model\n",
        "**optimizer:** algorithm to use to find the best weights that will make our model powerful\n",
        "\n",
        "**loss:** Loss function within our optimizer algorithm\n",
        "\n",
        "**metric:** critiria to evaluate the model\n",
        "\n",
        "In this case I will use Momentum"
      ],
      "metadata": {
        "id": "U48yor9gFQ1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "classifier.compile(optimizer = optimizer,loss= \"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tzgsP753F1sv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting the Model to Training Set\n",
        "**batch_size:** number of observations after which we upadte the weights. In fact, we are using **mini-batch gradient descent**\n",
        "\n",
        "**epochs:** how many times we train the model "
      ],
      "metadata": {
        "id": "5tKqDTK6Em4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train, y_train, batch_size = 64, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EYdEwbeEacR",
        "outputId": "d83787df-b07a-419d-ebbc-5b8853f718ff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 2ms/step - loss: 0.9177 - accuracy: 0.7692\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.8008\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.8119\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8176\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8227\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8310\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8419\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8490\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8493\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8537\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3875 - accuracy: 0.8459\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8464\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3856 - accuracy: 0.8468\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8529\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3837 - accuracy: 0.8496\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3802 - accuracy: 0.8529\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3774 - accuracy: 0.8494\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3773 - accuracy: 0.8516\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8514\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3780 - accuracy: 0.8525\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3731 - accuracy: 0.8561\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.8515\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3772 - accuracy: 0.8522\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3750 - accuracy: 0.8525\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8533\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8520\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3782 - accuracy: 0.8543\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8541\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8501\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8512\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.8533\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8519\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8496\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3752 - accuracy: 0.8522\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8533\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3728 - accuracy: 0.8534\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3758 - accuracy: 0.8495\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3737 - accuracy: 0.8521\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3735 - accuracy: 0.8543\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3785 - accuracy: 0.8503\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8501\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3743 - accuracy: 0.8506\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3723 - accuracy: 0.8500\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3795 - accuracy: 0.8486\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3828 - accuracy: 0.8479\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3722 - accuracy: 0.8516\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3732 - accuracy: 0.8504\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3734 - accuracy: 0.8485\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3719 - accuracy: 0.8543\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3726 - accuracy: 0.8568\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8520\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8535\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3714 - accuracy: 0.8528\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8526\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8530\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8554\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8541\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8518\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8485\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8561\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8505\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8520\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8499\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8541\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8529\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8536\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8535\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8490\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8454\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8531\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8512\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8514\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8515\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8547\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8501\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8518\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8503\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8531\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8514\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8518\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8521\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8550\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8531\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8556\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8487\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8526\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8495\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8371\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8415\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8518\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8541\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8506\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8531\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8522\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8516\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8530\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8494\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8496\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ac8695f90>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions\n",
        "I've trained the model and now it is time to see its capability on predecting futur churn result with test set "
      ],
      "metadata": {
        "id": "tA-URwk4IYIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_train = classifier.predict(X_train)\n",
        "#Threshold of 50%\n",
        "y_pred = (y_pred > 0.5)\n",
        "y_pred_train = (y_pred_train>0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buCeoT11HqTI",
        "outputId": "358c8455-3e51-4a06-f212-0823378e37b2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "nj3z4v8uJA_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fq9IwXjImjo",
        "outputId": "99661615-0cb8-4d2c-cdaa-b2cd336e4e97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1547,   48],\n",
              "       [ 226,  179]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1YNcPXxJKtp",
        "outputId": "4f35343a-a920-4f9f-97a3-5c3c4ec37070"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_train,y_pred_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhoudUPSJUH6",
        "outputId": "7a238890-4b07-4028-e4f8-679c2b93d909"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.858375"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUDbjQtjRRdF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Discussion\n",
        "In the above code, I managed to build a deep neural network with **4 Hidden Layers**. I used the mini-batch gradient descent with momentum and the result was acceptable. Furthermore, I managed to implement Batch Normalization as well as L2 regularization technique. \n",
        "\n",
        "It is time to make the code much originized by creating helper functions. Moreover, I will run multiple models with different optimization algorithms. Finally I will tune the hyperparameters and compare the perfremance of each model."
      ],
      "metadata": {
        "id": "459mmFCXWg7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model with Different Optimization Algorithms\n",
        "The following function is a helper function that will help us to kind of automate the creation of he model by choosing values of the different parameters"
      ],
      "metadata": {
        "id": "iiTWafq5fB9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to create model \n",
        "\n",
        "def model_create(X, Y, layers_dims, opt, lr = 0.01, mini_batch_size = 64, beta = 0.9,beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs=100):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    X -- input data, of shape (number of features, number of examples)\n",
        "    Y -- true \"label\" vector (1 for churn / 0 for not churn), of shape (1, number of examples)\n",
        "    opt -- the optimizer to be passed, momentum, adam, or rmsprop\n",
        "    layers_dims -- python list, containing the size of each layer\n",
        "    learning_rate -- the learning rate, scalar.\n",
        "    mini_batch_size -- the size of a mini batch\n",
        "    beta -- Momentum hyperparameter\n",
        "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
        "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
        "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
        "    num_epochs -- number of epochs\n",
        "\n",
        "  Returns:\n",
        "  model\n",
        "  \"\"\"\n",
        "  \n",
        "  model = Sequential()\n",
        "  #Input Layer\n",
        "  model.add(Dense(units = layers_dims[0], kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'relu', input_dim = 13 ))\n",
        "  model.add(BatchNormalization())\n",
        "  L = len(layers_dims)\n",
        "\n",
        "  #(N-2) Hidden Layer (the first hidden layer and the output layer are not included)\n",
        "  for i in range(1,L):\n",
        "    model.add(Dense(units = layers_dims[i], kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "  \n",
        "  #Output Layer\n",
        "  model.add(Dense(units = 1, kernel_initializer = 'he_uniform',kernel_regularizer='l2', activation = 'sigmoid'))\n",
        "  \n",
        "  #Optimization algorithms\n",
        "  if opt == 'momentum':\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=lr, momentum=beta)\n",
        "    model.compile(optimizer = optimizer,loss= \"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "  elif opt == 'adam':\n",
        "    #optimizer = keras.optimizers.Adam(lr,beta1,beta2,epsilon)\n",
        "    model.compile(optimizer = keras.optimizers.Adam(lr,beta1,beta2,epsilon),loss= \"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "  elif opt == 'rmsprop':\n",
        "     optimizer = keras.optimizers.RMSprop(learning_rate=lr, rho=beta2)\n",
        "     model.compile(optimizer = optimizer,loss= \"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "  #Fit the model\n",
        "  model.fit(X, Y, batch_size = mini_batch_size, epochs = num_epochs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "bz9aiyd9XvP2"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Function"
      ],
      "metadata": {
        "id": "H8MGdO4ufjzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predicts(model,train_set, test_set):\n",
        "  \"\"\"\n",
        "  Using the learned parameters, predicts a class for each example in training and testing set\n",
        "\n",
        "  Arguments:\n",
        "  model -- it is the model that was created by model_create()\n",
        "  train_set -- it is the training set that was used to train the model\n",
        "  test_set -- it is the training set that was used to test the model \n",
        "\n",
        "  Returns:\n",
        "  y_pred -- vector of predictions of our model using testing data set\n",
        "  y_pred_train -- vector of predictions of our model using training data set\n",
        "  \"\"\"\n",
        "  #Predicting the Test set results\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred_train = model.predict(X_train)\n",
        "  #Threshold of 50%\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  y_pred_train = (y_pred_train>0.5)\n",
        "  return y_pred, y_pred_train"
      ],
      "metadata": {
        "id": "lySSxjdUetvi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gK-isZcvfn49"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix\n",
        "How can we measure the effectiveness of our model. Better the effectiveness, better the performance, and this is exactly what we want. So, here where the role of confusion matrix comes into the limelight.\n",
        "Confusion Matrix is a performance measurement for machine learning classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values.\n",
        "\n",
        "**True Positive:**\n",
        "\n",
        "    - Interpretation: You predicted positive and itâ€™s true.\n",
        "\n",
        "    - You predicted that a woman is pregnant and she actually is.\n",
        "\n",
        "**True Negative:**\n",
        "\n",
        "    - Interpretation: You predicted negative and itâ€™s true.\n",
        "\n",
        "    - You predicted that a man is not pregnant and he actually is not.\n",
        "\n",
        "**False Positive: (Type 1 Error)**\n",
        "\n",
        "    - Interpretation: You predicted positive and itâ€™s false.\n",
        "\n",
        "    - You predicted that a man is pregnant but he actually is not.\n",
        "\n",
        "**False Negative: (Type 2 Error)**\n",
        "\n",
        "    - Interpretation: You predicted negative and itâ€™s false.\n",
        "\n",
        "    - You predicted that a woman is not pregnant but she actually is."
      ],
      "metadata": {
        "id": "j48daPM-hi6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function: Evaluate\n",
        "def evaluate(y_pred, y_pred_train, y_test, y_train):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  y_pred -- vector of predictions of our model using testing data set\n",
        "  y_pred_train -- vector of predictions of our model using training data set\n",
        "  y_test -- the true value from testing set\n",
        "  y_train -- the true value from training set\n",
        "  \"\"\"\n",
        "\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  print('The Confusion Matrix of the Model: \\n')\n",
        "  print(cm)\n",
        "  print('-------------------')\n",
        "  print('Train Accuracy: ',accuracy_score(y_train,y_pred_train))\n",
        "  print('Test Accuracy: ',accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "wKAAdC6GiJeg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Cases\n",
        " \n",
        "It's time to run the model and see how it performs on a Bank Churn dataset. By running the following code I will test the model with multiple hidden layer of $n_h$ hidden units! and using different optimization algorithms.\n",
        "\n",
        "### Run the Model with Adam"
      ],
      "metadata": {
        "id": "F_GXGAFlr2DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [6,6,6,1]\n",
        "model  = model_create(X_train, y_train, layers_dims,opt='adam')\n",
        "model_c = KerasClassifier(build_fn=model, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9EbrkJylOPf",
        "outputId": "186decc2-ddad-4631-9d9f-0218675815ae"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 3ms/step - loss: 0.7953 - accuracy: 0.7221\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8026\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8376\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8418\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8364\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8400\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8399\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8426\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8413\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8487\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8450\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8414\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8434\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8440\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8461\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8482\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8434\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8474\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8418\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8455\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8449\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8445\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8469\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8441\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8462\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8446\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8464\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8476\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8449\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8496\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8470\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8472\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8526\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8520\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8476\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8485\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8436\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8449\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8447\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8451\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8478\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8454\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8380\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8489\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8457\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8449\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8456\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8505\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8496\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8518\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8515\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8518\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8476\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8504\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8520\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8499\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8536\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8516\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8512\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8505\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8454\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8524\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8495\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8455\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8489\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8559\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8504\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8508\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8510\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8424\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8472\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8482\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8496\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8501\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8490\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8504\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8511\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8432\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8485\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8511\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8440\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8397\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8504\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8500\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8494\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8445\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8491\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8520\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8455\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8505\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8489\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8526\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8500\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8568\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8496\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8486\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8490\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8509\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_pred_train = predicts(model,X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWwiUlpdmL2p",
        "outputId": "6ad63fa9-f28a-471e-96d6-6a4c4eae218d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_pred, y_pred_train, y_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGXOvYe3pC4s",
        "outputId": "785473e8-9926-41f1-d68b-39bf01765bac"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Confusion Matrix of the Model: \n",
            "\n",
            "[[1494  101]\n",
            " [ 213  192]]\n",
            "-------------------\n",
            "Train Accuracy:  0.849875\n",
            "Test Accuracy:  0.843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Model with RMSProp"
      ],
      "metadata": {
        "id": "m8Sjgo2atCqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [6,6,6,1]\n",
        "model_momentum  = model_create(X_train, y_train, layers_dims,opt='momentum')\n",
        "model_c_momentum = KerasClassifier(build_fn=model, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO6pl1pgs_2P",
        "outputId": "096800d8-6e16-400b-d17f-5d1627369fbe"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 2ms/step - loss: 0.9126 - accuracy: 0.7685\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7960\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7984\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8194\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8326\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8336\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8425\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8424\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8499\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8456\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8470\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8469\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8382\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8476\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8464\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8466\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8472\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8491\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8472\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8476\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8494\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8486\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8503\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8490\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8489\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8466\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8504\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8508\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8468\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8486\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8481\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8500\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8485\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8445\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8481\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8469\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8490\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8480\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8506\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8487\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8515\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8474\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8460\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8478\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8494\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8493\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8470\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8479\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8512\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8529\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8450\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8476\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8528\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8485\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8475\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8512\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8494\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8515\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8500\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8489\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8470\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8478\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8495\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8506\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8460\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8460\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8495\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8493\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8511\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8503\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8476\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8514\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8491\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8500\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8491\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8459\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8464\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8521\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8514\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8520\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8464\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8480\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8534\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8518\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3776 - accuracy: 0.8511\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8504\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8491\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8494\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8435\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8509\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8553\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8474\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8479\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8499\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8496\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8482\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3792 - accuracy: 0.8501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_pred_train = predicts(model_momentum,X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flfG1g3ftU5w",
        "outputId": "5e3d6b81-0876-4c0b-ba02-cb847bfb017b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_pred, y_pred_train, y_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIXiA_2st6rz",
        "outputId": "a33c5714-7029-4445-ac33-93216178884e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Confusion Matrix of the Model: \n",
            "\n",
            "[[1528   67]\n",
            " [ 204  201]]\n",
            "-------------------\n",
            "Train Accuracy:  0.86375\n",
            "Test Accuracy:  0.8645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Model with RMSProp"
      ],
      "metadata": {
        "id": "db9skDkMuKl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [6,6,6,1]\n",
        "model_rmsprop  = model_create(X_train, y_train, layers_dims,opt='rmsprop')\n",
        "model_c_rmsprop = KerasClassifier(model=model, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKD97667t9Vl",
        "outputId": "36e33d5d-2f53-41d3-d2c0-1e28288764eb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 3ms/step - loss: 0.5279 - accuracy: 0.7940\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.5065 - accuracy: 0.7960\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7960\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7960\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7960\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7960\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7960\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7960\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7960\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7960\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7960\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7960\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_pred_train = predicts(model_rmsprop,X_train, X_test)"
      ],
      "metadata": {
        "id": "by_lEuKTuaTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fc287a-990b-4e3b-fd27-7db9dbfa6a0d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_pred, y_pred_train, y_test, y_train)"
      ],
      "metadata": {
        "id": "AI4bpR7euyOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17778595-a5ac-425f-a919-99d128a3725c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Confusion Matrix of the Model: \n",
            "\n",
            "[[1595    0]\n",
            " [ 405    0]]\n",
            "-------------------\n",
            "Train Accuracy:  0.796\n",
            "Test Accuracy:  0.7975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Results: Momentum Vs Adam Vs RMSProp\n",
        "In general, all the 3 models performed well. In fact, we have low bias and low variance in all the trained models which is something good. In fact, it seems that **momentum** have given the best perfermance so far. Next, I will use Random Grid Search to tune different hyperparameters and then comapre the perroramance of the different models. "
      ],
      "metadata": {
        "id": "G7LMaqK3vhem"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tes9QhOAu0ct"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning Hyperparameters\n",
        "### Lets Test How Tuning Hyperparameters works"
      ],
      "metadata": {
        "id": "ys_UZqhayRG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "Gj79XTxywUmF"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(optimizer):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ruCuWGPudy",
        "outputId": "63ed1bf1-05b6-4e21-ce19-8558c902540a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for batch size, epochs, and optimizer functions\n",
        "parameters = {'batch_size': [16, 32],\n",
        "              'optimizer': ['adam', 'rmsprop']}"
      ],
      "metadata": {
        "id": "7PFeu_xVPzCr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up Grid Search\n",
        "random_grid_search = RandomizedSearchCV(estimator = classifier,\n",
        "                           param_distributions = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "grid_search = random_grid_search.fit(X_train, y_train)\n",
        "best_parameters = random_grid_search.best_params_\n",
        "best_accuracy = random_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V05HU5vUP2p8",
        "outputId": "39bee26e-6a4b-40b6-d9e3-218ad62eec24"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "450/450 [==============================] - 1s 2ms/step - loss: 0.6407 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5157 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5573 - accuracy: 0.7921\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7940\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.7969\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "450/450 [==============================] - 2s 2ms/step - loss: 0.5260 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5221 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7964\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5158 - accuracy: 0.7975\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7924\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7940\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5862 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7960\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.7953\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.7919\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5849 - accuracy: 0.7964\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5798 - accuracy: 0.7932\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.7935\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5878 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5890 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.7929\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5860 - accuracy: 0.7942\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5893 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5842 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6091 - accuracy: 0.7928\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7939\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6128 - accuracy: 0.7943\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6013 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6089 - accuracy: 0.7936\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6022 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best parameters\n",
        "best_parameters"
      ],
      "metadata": {
        "id": "46zZp0eHP5m4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066e8c6d-1bde-4dc2-ac1c-5adb2bc90662"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'adam', 'batch_size': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best average\n",
        "print('Best average: ', ('%.4f' % best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4iorefefgav",
        "outputId": "895e71e5-8fc3-435c-f472-aa09fab5688d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best average:  0.7960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try another set pf values for hyperparamaters"
      ],
      "metadata": {
        "id": "lvncGnQ7gI1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for batch size, epochs, and optimizer functions\n",
        "parameters = {'batch_size': [16, 32,64],\n",
        "              'optimizer': ['adam', 'momentum','rmsprop']}"
      ],
      "metadata": {
        "id": "GwVXbEE8flY1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up Grid Search\n",
        "random_grid_search = RandomizedSearchCV(estimator = classifier,\n",
        "                           param_distributions = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "grid_search = random_grid_search.fit(X_train, y_train)\n",
        "best_parameters = random_grid_search.best_params_\n",
        "best_accuracy = random_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkfbvDbTgUqO",
        "outputId": "37a575d2-6747-4717-bd5d-372b1611dc92"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "450/450 [==============================] - 2s 2ms/step - loss: 0.5109 - accuracy: 0.7965\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7940\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7964\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7937\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7939\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7968\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7953\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7967\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7975\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7935\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "450/450 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6269 - accuracy: 0.7942\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.7932\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5798 - accuracy: 0.7932\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6147 - accuracy: 0.7921\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5793 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5790 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.5930 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.7935\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.7964\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.7939\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6169 - accuracy: 0.7958\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.7937\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5863 - accuracy: 0.7937\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.7965\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.7950\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.7939\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6541 - accuracy: 0.7960\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6664 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6663 - accuracy: 0.7914\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6524 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.7921\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6519 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6732 - accuracy: 0.7929\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6667 - accuracy: 0.7906\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6590 - accuracy: 0.7928\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6679 - accuracy: 0.7926\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6406 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6484 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6530 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6679 - accuracy: 0.7928\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6439 - accuracy: 0.7936\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6714 - accuracy: 0.7893\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6552 - accuracy: 0.7933\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6589 - accuracy: 0.7911\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6566 - accuracy: 0.7950\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "113/113 [==============================] - 1s 2ms/step - loss: 0.6566 - accuracy: 0.7922\n",
            "25/25 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "30 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 236, in fit\n",
            "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\", line 155, in fit\n",
            "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
            "  File \"<ipython-input-50-76d0ebaa6485>\", line 6, in build_classifier\n",
            "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\", line 563, in class_and_config_for_serialized_keras_object\n",
            "    f'Unknown {printable_module_name}: {class_name}. Please ensure this '\n",
            "ValueError: Unknown optimizer: momentum. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.796   nan 0.796 0.796   nan 0.796 0.796   nan 0.796]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best parameters\n",
        "best_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdFgFADkgXeQ",
        "outputId": "774486e3-5a0d-49df-8bab-ffdf05620a72"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'adam', 'batch_size': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best average\n",
        "print('Best average: ', ('%.4f' % best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yigfjy-Ag0-z",
        "outputId": "23a95120-baf3-407e-a693-003aae1349da"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best average:  0.7960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tune Learning Rate and Momentum"
      ],
      "metadata": {
        "id": "AfeCoTVYhwNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(lr, momentum):\n",
        "    classifier_m = Sequential()\n",
        "    classifier_m.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
        "    classifier_m.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier_m.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier_m.compile(optimizer = keras.optimizers.SGD(lr,momentum), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier_m\n",
        "classifier_m = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "learn_rate = [0.001, 0.01, 0.1]\n",
        "momentum = [0.9, 0.99, 0.999]\n",
        "parameters = dict(lr=learn_rate,momentum=momentum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiO3B9G0g44N",
        "outputId": "6bc31fe7-f72c-47c6-df1d-e5b9a24fcc3a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up Grid Search\n",
        "random_grid_search = RandomizedSearchCV(estimator = classifier_m,\n",
        "                           param_distributions = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "random_grid_search = random_grid_search.fit(X_train, y_train)\n",
        "best_parameters = random_grid_search.best_params_\n",
        "best_accuracy = random_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8ofHuykjo-q",
        "outputId": "559b31d9-af70-4ae5-933f-1c50f0760e32"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6264 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6265 - accuracy: 0.7953\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6269 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.7975\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6277 - accuracy: 0.7926\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6274 - accuracy: 0.7904\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6265 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6267 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.7950\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.7967\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7960\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5573 - accuracy: 0.7975\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7929\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7933\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7972\n",
            "25/25 [==============================] - 1s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.7915\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5560 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5846 - accuracy: 0.7968\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.7940\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7937\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.7918\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5783 - accuracy: 0.7921\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5800 - accuracy: 0.7932\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5769 - accuracy: 0.7929\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5774 - accuracy: 0.7932\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7922\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.7937\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7953\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5278 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5503 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.7942\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7926\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7925\n",
            "25/25 [==============================] - 1s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5524 - accuracy: 0.7968\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7933\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7967\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5796 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5780 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5848 - accuracy: 0.7918\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5848 - accuracy: 0.7942\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5757 - accuracy: 0.7950\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5781 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6071 - accuracy: 0.7554\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5124 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7943\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7975\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.7933\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7919\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7950\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7957\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7953\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5605 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7971\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7937\n",
            "25/25 [==============================] - 1s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7937\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5780 - accuracy: 0.7925\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7943\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7965\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7936\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5838 - accuracy: 0.7908\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5866 - accuracy: 0.7819\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7918\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.6350 - accuracy: 0.7372\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.7854\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5784 - accuracy: 0.7858\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "225/225 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7944\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.7960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best parameters\n",
        "best_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzokBq_jqWt",
        "outputId": "2b6fbc76-de14-495e-fa9e-6efae554c0aa"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'momentum': 0.9, 'lr': 0.001}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best average\n",
        "print('Best average: ', ('%.4f' % best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGYZgy0ami9k",
        "outputId": "f0e9124c-ddd7-442f-cf72-9e50547d54da"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best average:  0.7960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets Try Tining Hyperparameters on our Models"
      ],
      "metadata": {
        "id": "ToM7ZbF9mnTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning Adam Model"
      ],
      "metadata": {
        "id": "us0GWposnUZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to create model with adam \n",
        "\n",
        "def build_adam(learning_rate,beta_1, beta_2,  epsilon):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    learning_rate -- the learning rate, scalar.\n",
        "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
        "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
        "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
        "\n",
        "  Returns:\n",
        "  model\n",
        "  \"\"\"\n",
        "  \n",
        "  classifier_adam = Sequential()\n",
        "  classifier_adam.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu', input_dim = 13))\n",
        "  classifier_adam.add(BatchNormalization())\n",
        "  classifier_adam.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_adam.add(BatchNormalization())\n",
        "  classifier_adam.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_adam.add(BatchNormalization())\n",
        "  classifier_adam.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_adam.add(BatchNormalization())\n",
        "  classifier_adam.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_adam.add(BatchNormalization())\n",
        "  classifier_adam.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "  classifier_adam.compile(optimizer = keras.optimizers.Adam(learning_rate=learning_rate,beta_1=beta_1,beta_2=beta_2,epsilon=epsilon), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return classifier_adam\n",
        "\n",
        "classifier_adam = KerasClassifier(build_fn = build_adam)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVvdTXZzmsWC",
        "outputId": "d13e6d4f-9a49-4958-b1d1-5d9c1f33f037"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "beta_1 = [0.9, 0.99, 0.999]\n",
        "beta_2 = [0.997,0.998,0.999]\n",
        "epsilon = [1e-8]\n",
        "parameters = dict(learning_rate=learning_rate,beta_1=beta_1, beta_2=beta_2,epsilon=epsilon)\n",
        "# Setting up Random Grid Search\n",
        "random_grid_search = RandomizedSearchCV(estimator = classifier_adam,\n",
        "                           param_distributions = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "random_grid_search = random_grid_search.fit(X_train, y_train)\n",
        "best_parameters = random_grid_search.best_params_\n",
        "best_accuracy = random_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE1KzdBZs_NA",
        "outputId": "9110a3e6-0987-45d7-b5b9-d171448c3c24"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5898 - accuracy: 0.7942\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6105 - accuracy: 0.7907\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5799 - accuracy: 0.7989\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5840 - accuracy: 0.7994\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6038 - accuracy: 0.7857\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5938 - accuracy: 0.7890\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5777 - accuracy: 0.7910\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5811 - accuracy: 0.7846\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5994 - accuracy: 0.7858\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 4ms/step - loss: 0.5960 - accuracy: 0.7982\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.1124 - accuracy: 0.7271\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.1033 - accuracy: 0.7193\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.1110 - accuracy: 0.7011\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0992 - accuracy: 0.7211\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0344 - accuracy: 0.7132\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0513 - accuracy: 0.7211\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.1502 - accuracy: 0.6933\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0909 - accuracy: 0.6829\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0848 - accuracy: 0.7411\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0891 - accuracy: 0.6651\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5829 - accuracy: 0.7897\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6104 - accuracy: 0.7781\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5970 - accuracy: 0.7875\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5947 - accuracy: 0.7818\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5959 - accuracy: 0.7821\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5890 - accuracy: 0.7964\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5816 - accuracy: 0.7821\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6054 - accuracy: 0.7812\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6139 - accuracy: 0.7761\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5818 - accuracy: 0.7907\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7553 - accuracy: 0.7932\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7244 - accuracy: 0.7929\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6979 - accuracy: 0.7912\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6799 - accuracy: 0.7928\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 4s 3ms/step - loss: 0.6683 - accuracy: 0.7803\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7017 - accuracy: 0.7896\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6576 - accuracy: 0.7914\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6480 - accuracy: 0.7896\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6863 - accuracy: 0.7882\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6919 - accuracy: 0.7847\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7455 - accuracy: 0.7897\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7852 - accuracy: 0.7906\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7416 - accuracy: 0.7882\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7298 - accuracy: 0.7900\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7902 - accuracy: 0.7914\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7272 - accuracy: 0.7865\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7585 - accuracy: 0.7950\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7093 - accuracy: 0.7911\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7434 - accuracy: 0.7900\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7723 - accuracy: 0.7818\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5340 - accuracy: 0.7928\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5674 - accuracy: 0.7915\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5800 - accuracy: 0.7914\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5888 - accuracy: 0.7918\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5873 - accuracy: 0.7894\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5658 - accuracy: 0.7911\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5580 - accuracy: 0.7940\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5859 - accuracy: 0.7915\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5747 - accuracy: 0.7924\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.7876\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5863 - accuracy: 0.7875\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5880 - accuracy: 0.7837\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6050 - accuracy: 0.7772\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6229 - accuracy: 0.7867\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5953 - accuracy: 0.7964\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5824 - accuracy: 0.7904\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6029 - accuracy: 0.7826\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6327 - accuracy: 0.7967\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5761 - accuracy: 0.7925\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5875 - accuracy: 0.7946\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.7879\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6991 - accuracy: 0.7918\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6303 - accuracy: 0.7903\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7556 - accuracy: 0.7896\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6320 - accuracy: 0.7897\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "225/225 [==============================] - 3s 4ms/step - loss: 0.6869 - accuracy: 0.7851\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "225/225 [==============================] - 3s 4ms/step - loss: 0.6821 - accuracy: 0.7875\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6418 - accuracy: 0.7943\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6991 - accuracy: 0.7875\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7983 - accuracy: 0.7906\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5660 - accuracy: 0.7924\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5643 - accuracy: 0.7921\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5986 - accuracy: 0.7918\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7935\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5694 - accuracy: 0.7885\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5826 - accuracy: 0.7862\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5964 - accuracy: 0.7907\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5569 - accuracy: 0.7935\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7910\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5762 - accuracy: 0.7928\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6035 - accuracy: 0.7904\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5833 - accuracy: 0.7897\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5987 - accuracy: 0.7912\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6107 - accuracy: 0.7869\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5841 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5820 - accuracy: 0.7933\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6116 - accuracy: 0.7878\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5788 - accuracy: 0.7960\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5801 - accuracy: 0.7935\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5851 - accuracy: 0.7890\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 2s 3ms/step - loss: 0.5727 - accuracy: 0.8061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best parameters for adam\n",
        "best_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gqH-jy-tgue",
        "outputId": "09c49fbc-8ab8-447c-d547-04cc26113954"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.01, 'epsilon': 1e-08, 'beta_2': 0.998, 'beta_1': 0.9}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best average for adam\n",
        "print('Best average: ', ('%.4f' % best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwbvcmH7x1zY",
        "outputId": "01bdaf79-1eb2-453f-97a5-b1b84bf88056"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best average:  0.7960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning Momentum Model\n"
      ],
      "metadata": {
        "id": "WD0fLdR3x9F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to create model with adam \n",
        "\n",
        "def build_momentum(learning_rate,momentum):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    learning_rate -- the learning rate, scalar.\n",
        "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
        "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
        "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
        "\n",
        "  Returns:\n",
        "  model\n",
        "  \"\"\"\n",
        "  \n",
        "  classifier_momentum = Sequential()\n",
        "  classifier_momentum.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu', input_dim = 13))\n",
        "  classifier_momentum.add(BatchNormalization())\n",
        "  classifier_momentum.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_momentum.add(BatchNormalization())\n",
        "  classifier_momentum.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_momentum.add(BatchNormalization())\n",
        "  classifier_momentum.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_momentum.add(BatchNormalization())\n",
        "  classifier_momentum.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_momentum.add(BatchNormalization())\n",
        "  classifier_momentum.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "  classifier_momentum.compile(optimizer = keras.optimizers.SGD(learning_rate=learning_rate,momentum=momentum), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return classifier_momentum\n",
        "\n",
        "classifier_momentum = KerasClassifier(build_fn = build_momentum)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68eV2va_x6bX",
        "outputId": "c3f9186d-be57-4e34-c56a-6fd66b8d25b8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "momentum = [0.9, 0.99, 0.999]\n",
        "parameters = dict(learning_rate=learning_rate,momentum=momentum)\n",
        "# Setting up Random Grid Search\n",
        "random_grid_search = RandomizedSearchCV(estimator = classifier_momentum,\n",
        "                           param_distributions = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "random_grid_search = random_grid_search.fit(X_train, y_train)\n",
        "best_parameters = random_grid_search.best_params_\n",
        "best_accuracy = random_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWaA1IP3ygOg",
        "outputId": "6de1e559-2b59-455d-b1f1-64e341fb9132"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1990 - accuracy: 0.7535\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.2228 - accuracy: 0.7586\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1976 - accuracy: 0.7494\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.2017 - accuracy: 0.7589\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1474 - accuracy: 0.7454\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.2144 - accuracy: 0.7743\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.1995 - accuracy: 0.7697\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1347 - accuracy: 0.7654\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1983 - accuracy: 0.7646\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.2342 - accuracy: 0.7535\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 2ms/step - loss: 1.0617 - accuracy: 0.7771\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.9887 - accuracy: 0.7707\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0209 - accuracy: 0.7765\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0816 - accuracy: 0.7733\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0668 - accuracy: 0.7597\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0203 - accuracy: 0.7718\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0463 - accuracy: 0.7758\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0294 - accuracy: 0.7736\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0487 - accuracy: 0.7742\n",
            "25/25 [==============================] - 1s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0268 - accuracy: 0.7736\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0257 - accuracy: 0.7783\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9830 - accuracy: 0.7782\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0500 - accuracy: 0.7742\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 4ms/step - loss: 1.0178 - accuracy: 0.7765\n",
            "25/25 [==============================] - 1s 5ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0394 - accuracy: 0.7679\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9336 - accuracy: 0.7689\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0094 - accuracy: 0.7719\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 2ms/step - loss: 0.9996 - accuracy: 0.7776\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0608 - accuracy: 0.7699\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9940 - accuracy: 0.7808\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.9859 - accuracy: 0.7894\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9345 - accuracy: 0.7869\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9359 - accuracy: 0.7876\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9107 - accuracy: 0.7876\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.9052 - accuracy: 0.7871\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9533 - accuracy: 0.7892\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.8919 - accuracy: 0.7882\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9293 - accuracy: 0.7865\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.9364 - accuracy: 0.7981\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9000 - accuracy: 0.7875\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.7367 - accuracy: 0.7885\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.7358 - accuracy: 0.7861\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.7435 - accuracy: 0.7933\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7589 - accuracy: 0.7847\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 2ms/step - loss: 0.7708 - accuracy: 0.7860\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7175 - accuracy: 0.7875\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.7429 - accuracy: 0.7853\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.7712 - accuracy: 0.7821\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.7484 - accuracy: 0.7826\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.7756 - accuracy: 0.7900\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.9922 - accuracy: 0.7899\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0955 - accuracy: 0.7832\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.1324 - accuracy: 0.7790\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9995 - accuracy: 0.7926\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.1245 - accuracy: 0.7815\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.9841 - accuracy: 0.7669\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.1414 - accuracy: 0.7871\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.0830 - accuracy: 0.7803\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1036 - accuracy: 0.7844\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.1162 - accuracy: 0.7828\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.5869 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6052 - accuracy: 0.7906\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.6069 - accuracy: 0.7987\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5885 - accuracy: 0.7961\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.6061 - accuracy: 0.7925\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.5952 - accuracy: 0.7883\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.6055 - accuracy: 0.7900\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 0.5834 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 0.5992 - accuracy: 0.7962\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 2ms/step - loss: 0.5862 - accuracy: 0.7996\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.2878 - accuracy: 0.7826\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 194.7039 - accuracy: 0.7487\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.5322 - accuracy: 0.7735\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0114 - accuracy: 0.7881\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 2.0345 - accuracy: 0.7518\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.2232 - accuracy: 0.7568\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.4893 - accuracy: 0.7661\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 3ms/step - loss: 1.4570 - accuracy: 0.7758\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 2ms/step - loss: 1.1637 - accuracy: 0.7856\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 1.0656 - accuracy: 0.7878\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 2.7165 - accuracy: 0.7467\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 2.8036 - accuracy: 0.7469\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 2.3332 - accuracy: 0.7490\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 7.9401 - accuracy: 0.7526\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 79.0805 - accuracy: 0.6978\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 7.9591 - accuracy: 0.7099\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 3.9759 - accuracy: 0.7294\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 9.9411 - accuracy: 0.7346\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 7.2889 - accuracy: 0.7307\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 2s 2ms/step - loss: 4.6949 - accuracy: 0.7435\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 2s 3ms/step - loss: 0.5935 - accuracy: 0.7972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best parameters for momentum\n",
        "best_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1YCXKjryr99",
        "outputId": "755e8165-b1b4-4e30-bc44-e3826cc64d64"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'momentum': 0.9, 'learning_rate': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best average for momentum\n",
        "print('Best average: ', ('%.4f' % best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr_r0eV1zw-r",
        "outputId": "566a2c42-903a-4131-d9ce-d9666ee3ebde"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best average:  0.7984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning RMSprop"
      ],
      "metadata": {
        "id": "Zo0s7XsGz4xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to create model with adam \n",
        "\n",
        "def build_rmsprop(learning_rate,rho):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    learning_rate -- the learning rate, scalar.\n",
        "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
        "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
        "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
        "\n",
        "  Returns:\n",
        "  model\n",
        "  \"\"\"\n",
        "  \n",
        "  classifier_rmsprop = Sequential()\n",
        "  classifier_rmsprop.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu', input_dim = 13))\n",
        "  classifier_rmsprop.add(BatchNormalization())\n",
        "  classifier_rmsprop.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_rmsprop.add(BatchNormalization())\n",
        "  classifier_rmsprop.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_rmsprop.add(BatchNormalization())\n",
        "  classifier_rmsprop.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_rmsprop.add(BatchNormalization())\n",
        "  classifier_rmsprop.add(Dense(units = 6, kernel_initializer = 'he_uniform', kernel_regularizer='l2',activation = 'relu'))\n",
        "  classifier_rmsprop.add(BatchNormalization())\n",
        "  classifier_rmsprop.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "  classifier_rmsprop.compile(optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate,rho=rho), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  return classifier_rmsprop\n",
        "\n",
        "classifier_rmsprop = KerasClassifier(build_fn = build_rmsprop)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztJ3yGXBz1Zu",
        "outputId": "0139cc85-24b4-4ca7-877d-becd4cd64281"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "rho= [0.9, 0.99, 0.999]\n",
        "parameters = dict(learning_rate=learning_rate,rho=rho)\n",
        "# Setting up Random Grid Search\n",
        "random_grid_search = RandomizedSearchCV(estimator = classifier_rmsprop,\n",
        "                           param_distributions = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "random_grid_search = random_grid_search.fit(X_train, y_train)\n",
        "best_parameters = random_grid_search.best_params_\n",
        "best_accuracy = random_grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wJSjvWA0QKj",
        "outputId": "6254b5be-87f3-491c-d077-96d53a69660a"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0030 - accuracy: 0.7047\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0349 - accuracy: 0.7468\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0790 - accuracy: 0.6961\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0549 - accuracy: 0.6965\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0300 - accuracy: 0.7182\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0780 - accuracy: 0.7067\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0869 - accuracy: 0.7075\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0734 - accuracy: 0.7281\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 4s 3ms/step - loss: 1.0981 - accuracy: 0.7531\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.0419 - accuracy: 0.7550\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9506 - accuracy: 0.7733\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9599 - accuracy: 0.7449\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.8885 - accuracy: 0.7572\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9386 - accuracy: 0.7519\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9227 - accuracy: 0.7497\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9120 - accuracy: 0.7435\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9104 - accuracy: 0.7551\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9348 - accuracy: 0.7535\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 5s 3ms/step - loss: 0.9753 - accuracy: 0.7239\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.9450 - accuracy: 0.7618\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6337 - accuracy: 0.7990\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6548 - accuracy: 0.7857\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6729 - accuracy: 0.7876\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6659 - accuracy: 0.7861\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6466 - accuracy: 0.7908\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6447 - accuracy: 0.7993\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6528 - accuracy: 0.7953\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6398 - accuracy: 0.7818\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6939 - accuracy: 0.7931\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6418 - accuracy: 0.7981\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5850 - accuracy: 0.7904\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5519 - accuracy: 0.8037\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6016 - accuracy: 0.7924\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5972 - accuracy: 0.7910\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 4s 3ms/step - loss: 0.6166 - accuracy: 0.7837\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 4s 4ms/step - loss: 0.5734 - accuracy: 0.7847\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5840 - accuracy: 0.7981\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5730 - accuracy: 0.7907\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5572 - accuracy: 0.8015\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5864 - accuracy: 0.7987\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5144 - accuracy: 0.7956\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5056 - accuracy: 0.8015\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.4995 - accuracy: 0.7982\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5110 - accuracy: 0.7989\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5136 - accuracy: 0.7979\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5160 - accuracy: 0.7907\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5260 - accuracy: 0.8007\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5175 - accuracy: 0.7949\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.4894 - accuracy: 0.8079\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5086 - accuracy: 0.8035\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.4990 - accuracy: 0.7924\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5119 - accuracy: 0.7939\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.4986 - accuracy: 0.7951\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 4s 5ms/step - loss: 0.4956 - accuracy: 0.7985\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5118 - accuracy: 0.7924\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.4991 - accuracy: 0.7974\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5028 - accuracy: 0.7947\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5021 - accuracy: 0.8012\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.4806 - accuracy: 0.7996\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5124 - accuracy: 0.7990\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5569 - accuracy: 0.7919\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5555 - accuracy: 0.7954\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5515 - accuracy: 0.7919\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5479 - accuracy: 0.7942\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5568 - accuracy: 0.7886\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5434 - accuracy: 0.7879\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5489 - accuracy: 0.7910\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5414 - accuracy: 0.7906\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5397 - accuracy: 0.7939\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5539 - accuracy: 0.7897\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5954 - accuracy: 0.7917\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.5784 - accuracy: 0.7897\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6087 - accuracy: 0.7915\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6050 - accuracy: 0.7896\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6117 - accuracy: 0.7876\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6447 - accuracy: 0.7890\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6125 - accuracy: 0.7931\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.8565 - accuracy: 0.7911\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6268 - accuracy: 0.7862\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 0.6484 - accuracy: 0.7910\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 2.5371 - accuracy: 0.7728\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.2354 - accuracy: 0.7860\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.7655 - accuracy: 0.7872\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.6790 - accuracy: 0.7806\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.7312 - accuracy: 0.7750\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.7027 - accuracy: 0.7817\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.8453 - accuracy: 0.7869\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.3929 - accuracy: 0.7856\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.2101 - accuracy: 0.7894\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "225/225 [==============================] - 3s 3ms/step - loss: 1.5472 - accuracy: 0.7757\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 3s 3ms/step - loss: 1.0772 - accuracy: 0.6894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best parameters for rmsprop\n",
        "best_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B13tzkIR0ab8",
        "outputId": "7dc16554-9e4b-4b9b-de98-ebdd1fe51f40"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rho': 0.9, 'learning_rate': 0.001}"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting our best average for rmsprop\n",
        "print('Best average: ', ('%.4f' % best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r1HnEqw2C4b",
        "outputId": "e146468c-8ea3-444f-9888-72e397050c83"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best average:  0.7987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try different Models with the Tuned Hyperparameters"
      ],
      "metadata": {
        "id": "grSGYZQJ2INV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam Optimizer"
      ],
      "metadata": {
        "id": "YdwdtH5P2isO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [6,6,6,1]\n",
        "\n",
        "model_adam  = model_create(X_train, y_train, layers_dims,opt='adam',lr=0.01,beta1 = 0.9, beta2 = 0.998,  epsilon = 1e-8,)\n",
        "model_a = KerasClassifier(build_fn=model_adam, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-mzllph2HA3",
        "outputId": "4b673983-0d53-4814-af32-8c3631a2f30f"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 3ms/step - loss: 0.6440 - accuracy: 0.7804\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8290\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8438\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8476\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8465\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8479\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8443\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8478\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8466\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8475\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8511\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8503\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8490\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8471\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8431\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8468\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8461\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8484\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8493\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8474\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8487\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8370\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8438\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8435\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8525\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8480\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8480\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8479\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8466\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8438\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8441\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8508\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8474\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8475\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8496\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8472\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8485\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8478\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8479\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8480\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8495\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8460\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8484\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8519\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8485\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8481\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8514\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8484\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8447\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8478\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8479\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8489\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8490\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8503\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8414\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8490\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8471\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8489\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8469\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8515\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8457\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8508\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8470\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8434\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8504\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8476\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8481\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8500\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8445\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8495\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8453\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8490\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8466\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8481\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8490\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8476\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8462\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8503\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8469\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8470\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8470\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8431\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8457\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8535\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8471\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8478\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8475\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8478\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8478\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8474\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8486\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8500\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8464\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8509\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8501\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8504\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3754 - accuracy: 0.8464\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8510\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_pred_train = predicts(model_adam,X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUPxj_2O3x5k",
        "outputId": "949f9cec-02b9-4123-8d5e-f2968d41be58"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_pred, y_pred_train, y_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1asFhrmc3hUD",
        "outputId": "a0fe8223-083c-4b08-a25f-069955185f7b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Confusion Matrix of the Model: \n",
            "\n",
            "[[1508   87]\n",
            " [ 206  199]]\n",
            "-------------------\n",
            "Train Accuracy:  0.855875\n",
            "Test Accuracy:  0.8535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum Optimizer"
      ],
      "metadata": {
        "id": "Z9x2ULSr32wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [6,6,6,1]\n",
        "\n",
        "model_momentum  = model_create(X_train, y_train, layers_dims,opt='momentum',lr=0.01,beta=0.9)\n",
        "model_m = KerasClassifier(build_fn=model_momentum, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OtV0k4a3z13",
        "outputId": "1086a4fa-e30c-45eb-a974-4d699d9194e7"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 3s 2ms/step - loss: 0.8844 - accuracy: 0.7571\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.8230\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8251\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8288\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8394\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8439\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8445\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8456\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8496\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8438\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8462\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8501\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8499\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8472\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8489\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8493\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8475\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8472\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8530\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8446\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8560\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8490\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8515\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8543\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8474\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8514\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8509\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8508\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8537\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8531\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8510\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8508\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8531\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8530\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8504\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8518\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8481\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8478\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8491\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8526\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8506\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8549\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8499\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8510\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8537\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8508\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8522\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8525\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8506\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8506\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8519\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8543\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8571\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8550\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8550\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8519\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8509\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8549\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8531\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8501\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8553\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8519\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8529\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8559\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8553\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8482\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8531\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8536\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8536\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8533\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8526\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8536\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8540\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8546\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8536\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8531\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8512\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8514\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8522\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8531\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8554\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8535\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8503\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8514\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8568\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8530\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8591\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8528\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8516\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8500\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8541\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8550\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8541\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8508\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8534\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8528\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_pred_train = predicts(model_momentum,X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-hD0w9D4MBb",
        "outputId": "ffdda915-f703-4aeb-84a9-731b4bc49144"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "250/250 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_pred, y_pred_train, y_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jesWwjS34gIV",
        "outputId": "224945aa-a507-46c2-acdb-7e24d23337ff"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Confusion Matrix of the Model: \n",
            "\n",
            "[[1509   86]\n",
            " [ 206  199]]\n",
            "-------------------\n",
            "Train Accuracy:  0.85925\n",
            "Test Accuracy:  0.854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers_dims = [6,6,6,1]\n",
        "\n",
        "model_rmsprop  = model_create(X_train, y_train, layers_dims,opt='rmsprop',lr=0.001,beta2=0.9)\n",
        "model_r = KerasClassifier(build_fn=model_rmsprop, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0assvSnN4itm",
        "outputId": "04ba36cf-e121-46c8-d3b3-d8e2b06155c6"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 3s 2ms/step - loss: 1.0006 - accuracy: 0.4235\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.8496 - accuracy: 0.7914\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.7304 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7960\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7960\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7960\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7960\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7960\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7949\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7979\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8245\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8331\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8404\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8404\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8439\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8474\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8490\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8516\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8518\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8516\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8544\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8546\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8560\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8574\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8570\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3729 - accuracy: 0.8565\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8610\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8589\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8569\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8590\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8560\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8565\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8585\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8583\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8596\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8600\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8599\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8576\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8625\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8569\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8600\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8544\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8589\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8589\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8571\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8558\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8576\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8581\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8570\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8577\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8568\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8590\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8581\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8610\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8586\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8599\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8579\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8571\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8559\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8587\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8594\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8627\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8596\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8576\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8571\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8572\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8571\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8569\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8599\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8611\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8585\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8609\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8600\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8590\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8606\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8616\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8577\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8610\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8589\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8597\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8599\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8602\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8635\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8596\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8612\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8604\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8583\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8600\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8609\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8609\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8604\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8586\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8614\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8609\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8636\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8571\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8593\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8612\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8599\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_pred_train = predicts(model_momentum,X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNltSGBF5Iut",
        "outputId": "80b44ae5-8cb3-4ff0-a4ee-a02b88e7a056"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step\n",
            "250/250 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_pred, y_pred_train, y_test, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKfEl41S5Vvb",
        "outputId": "386f7c7a-4109-44dd-e772-37f712609015"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Confusion Matrix of the Model: \n",
            "\n",
            "[[1509   86]\n",
            " [ 206  199]]\n",
            "-------------------\n",
            "Train Accuracy:  0.85925\n",
            "Test Accuracy:  0.854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4pMCueS5ZJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Our original models scored almost 84% (all the three optimizer). In fact, with tuning hyperparameters, the models score was increased almost by 1%, which gives us up t 85%.\n",
        "\n",
        "To examine if there could be greater accuracy rates, it is possible to make improvements by raising the batch size and the epoch to 1000. However, A GPU would be required for this application because it will need much computation that I cannot afford it since I am using just i7-5600U and also google Colabs\n"
      ],
      "metadata": {
        "id": "0AFTsbCJ5mSK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zML03aJc6_lN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}